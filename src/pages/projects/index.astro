<!DOCTYPE html>
<html lang="en">

<head>
  
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5">
    
    <title>david</title>


    <meta name="title" content="david">
    <meta name="description" content="">
    
    <link rel="icon" type="image/x-icon" href="../favicon.jpg">
    <link rel="stylesheet" href="/index.css">
  
</head>

<body class="home">
  
    <header>
      <nav class="navbar">
          <a href="/">Home</a>
          <a href="/projects/">Projects</a>
          <a href="/blog/">Blog</a>
      </nav>
    </header>


    <h1>Projects</h1>
    <p><a href="https://github.com/44David/OpenLM">OpenLM</a> 
    <ul>
        <li>from scratch decoder-only transformer language model, writing everything from the layer norm to the multihead attention mechanisms.</li>
        <li>Wrote articles about the <a href="https://davids.onl/blog/mathematical-foundations-of-self-attention-mechanisms/">mathematics of self-attention mechanisms</a> & <a href="https://davids.onl/blog/%20mathematical-and-architectural-analysis-of-decoder-only-transformers/">decoder-only transformer models</a></li>
        <li>Implementation of "Language Models are Unsupervised Multitask Learners" (Radford et al.)</li>
    </ul>


    <p><a href="https://github.com/44David/qwen-reasoning-0.5B">qwen-0.5b-reasoning</a> | <a href="https://davids.onl/blog/inducing-reasoning-in-small-language-models/">article</a> | <a href="https://huggingface.co/44David/qwen-0.5b-reasoning-v2">v2 download</a></p>    
    <ul>
        <li>supervised fine tuned version of qwen2.5-0.5B</li>
        <li>demonstrated that small models with no reasoning capabilities can learn to create chain of thought thinking traces.</li>
        <li>created a custom symbolic chain-of-thought dataset using teacher model format</li>
        <li>Implementation of arXiv:2306.14050</li>
    </ul>

    <p><a href="https://huggingface.co/datasets/44David/SCoTD-deepseek-math-7B">SCoTD-deepseek-math-7B</a></p>
    <ul>
      <li>Custom dataset used for symbolic chain of thought distillation in smaller models.</li>
      <li>Entries include a MATH dataset question and 6 unique thinking traces for each question generated by deepseek-math-7B.</li>
      <li>300+ huggingface downloads.</li>
    </ul>

    <p><a href="https://github.com/stars/44David/lists/reinforcement-learning">Proximal Policy Optimization (PPO) & Critic-Actor agent architecture</a><p>
    <ul>
      <li>Implemented a reusable continuous and discrete PPO from scratch, with policy gradient clipping and GAE for advantage estimation</li>
      <li>Built and optimized reinforcement learning models using the critic-actor architecture for tasks like CartPole-v1 and HalfCheetah-v5</li>
    </ul>


    
    <p><a href="https://github.com/44David/hyprwindow">hyprwindow</a> Rust GTK-based minimal workspace & application manager for Wayland desktop environments</p>
    <p><a href="https://github.com/44David/Notate">Notate</a> image annotation service, annotate and store images in seconds</p>
    <p><a href="https://github.com/Arusai-Dev/dante-app">Dante</a> Truly free, fast and simple to use learning app based on proved spaced repetition learning algorithms </p>
    


    
</body>
</html>